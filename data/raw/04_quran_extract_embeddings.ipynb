{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd8394-c5e5-4093-be91-fa416cf62fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from pyarabic.araby import strip_diacritics\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4dd10-d118-4ae0-8820-a98c2cbd564e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "class OpenAIManager:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the OpenAIManager class with pre-defined languages, language detector,\n",
    "        OpenAI model, and a prompt template for translation.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.languages = [Language.ENGLISH, Language.ARABIC]\n",
    "        self.lang_detector = LanguageDetectorBuilder.from_languages(*self.languages).build()\n",
    "        self.openai_llm = OpenAI(temperature=0)\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"Translate the following arabic text into english : {query}\"\n",
    "        )\n",
    "        \n",
    "    def gpt3_embedding(self, content: str, engine: str = 'text-embedding-ada-002') -> list:\n",
    "        \"\"\"\n",
    "        Generates an embedding for the input content using OpenAI GPT-3.\n",
    "\n",
    "        Args:\n",
    "            content (str): The input content for which the embedding is required.\n",
    "            engine (str, optional): The engine to be used for generating the embedding. Defaults to 'text-embedding-ada-002'.\n",
    "\n",
    "        Returns:\n",
    "            list: The generated embedding as a list of floats.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = openai.Embedding.create(input=content, engine=engine)\n",
    "            vector = response['data'][0]['embedding']\n",
    "            return vector\n",
    "        except Exception as e:\n",
    "            logging.error(f'Embedding failed. Error message: {e}')\n",
    "\n",
    "    def extract_embedding(self, text: str) -> list:\n",
    "        \"\"\"\n",
    "        Extracts the embedding for the given text using GPT-3.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text for which the embedding is required.\n",
    "\n",
    "        Returns:\n",
    "            list: The extracted embedding as a list of floats.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            embedding = self.gpt3_embedding(text)\n",
    "        except:\n",
    "            while True:\n",
    "                try:\n",
    "                    if len(text) > 8191:\n",
    "                        logging.warning('[OPENAI ERROR] Trying to get shorter input < 8191 for text...')\n",
    "                        embedding = self.gpt3_embedding(text[:8191])\n",
    "                    else:\n",
    "                        embedding = self.gpt3_embedding(text)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    logging.error(f'Trying to get the embedding for text. Error message: {e}')\n",
    "                    time.sleep(5)\n",
    "        return embedding\n",
    "    \n",
    "    def translate(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Translates the input Arabic text to English using the OpenAI model.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input Arabic text to be translated.\n",
    "\n",
    "        Returns:\n",
    "            str: The translated English text.\n",
    "        \"\"\"\n",
    "        \n",
    "        translated_text = self.openai_llm(self.prompt.format(query=text))\n",
    "        return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406174fc-96ca-4c6b-8f1f-b5da8ca9cc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"Add your openai key\"\n",
    "openai_manager = OpenAIManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd9f7cd-2e7c-4911-ab68-65d1480c00e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_english_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess English text by converting to lowercase and removing non-alphanumeric characters.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "        str: The preprocessed text.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a567a-e9c6-4a5c-87bf-48ea9a8eec07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_json_data(json_file):\n",
    "    \"\"\"\n",
    "    Clean JSON data and extract GPT embeddings for each record.\n",
    "    \n",
    "    Args:\n",
    "        json_file (str): The input JSON file containing the data to clean and process.\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    cleaned_data = []\n",
    "    \n",
    "    for record in tqdm(data):\n",
    "        cleaned_record = record\n",
    "        # Extract the embedding for the input text\n",
    "        cleaned_record[\"embeddings\"] = openai_manager.extract_embedding(preprocess_english_text(\"english_translation\"))\n",
    "        cleaned_data.append(cleaned_record)\n",
    "\n",
    "    with open(\"quran_GPT_embeddings.json\", \"w\") as output_file:\n",
    "        json.dump(cleaned_data, output_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d831e67-da08-44f2-bd64-8d7e8ce84703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    json_file = \"quran/quran.json\"\n",
    "    clean_json_data(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded09a3-52f1-4a08-a9f0-18cf424ad549",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0829bba-3772-46c2-ad16-f9776d1cabd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
